{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in CSV: ['month', 'day', 'country', 'page1_main_category', 'colour', 'location', 'model_photography', 'page', 'avg_price', 'unique_products', 'browsing_depth', 'weekend', 'high_price_preference']\n",
      "Shape of data: (132379, 13)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "file_path = '../data/processed_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "print(\"Columns in CSV:\", data.columns.tolist())\n",
    "print(\"Shape of data:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of val before feature selection: (132379, 12)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "\n",
    "val = data.drop('avg_price', axis=1)\n",
    "tar = data['avg_price']\n",
    "print(\"Shape of val before feature selection:\", val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['high_price_preference', 'page1_main_category', 'browsing_depth', 'unique_products', 'model_photography', 'colour', 'location', 'page', 'country', 'weekend', 'month', 'day']\n",
      "Number of selected features: 12\n"
     ]
    }
   ],
   "source": [
    "# Feature selection with XGBRegressor\n",
    "\n",
    "fs = XGBRegressor(n_estimators=200, random_state=65)\n",
    "fs.fit(val, tar)\n",
    "selected = pd.DataFrame({\n",
    "    \"col\": val.columns,\n",
    "    \"sco\": fs.feature_importances_\n",
    "}).sort_values(\"sco\", ascending=False)[\"col\"].to_list()\n",
    "print(\"Selected features:\", selected)\n",
    "print(\"Number of selected features:\", len(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of val after feature selection: (132379, 12)\n"
     ]
    }
   ],
   "source": [
    "val = val[selected]\n",
    "print(\"Shape of val after feature selection:\", val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train before scaling: (105903, 12)\n",
      "Shape of x_test before scaling: (26476, 12)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "\n",
    "x_train, x_test, tr_lab, ts_lab = train_test_split(val, tar, test_size=0.2, random_state=65)\n",
    "print(\"Shape of x_train before scaling:\", x_train.shape)\n",
    "print(\"Shape of x_test before scaling:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train after scaling: (105903, 12)\n",
      "Shape of x_test after scaling: (26476, 12)\n"
     ]
    }
   ],
   "source": [
    "# Scale data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "print(\"Shape of x_train after scaling:\", x_train.shape)\n",
    "print(\"Shape of x_test after scaling:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building functions\n",
    "\n",
    "def build_linear_regression(x_train, x_test, tr_lab, ts_lab):\n",
    "    print('\\n----------Building Linear Regression----------')\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train, tr_lab)\n",
    "    ts_pred = lr.predict(x_test)\n",
    "    rmse = root_mean_squared_error(ts_lab, ts_pred)\n",
    "    mse = mean_squared_error(ts_lab, ts_pred)\n",
    "    mae = mean_absolute_error(ts_lab, ts_pred)\n",
    "    r2 = r2_score(ts_lab, ts_pred)\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ridge_regression(x_train, x_test, tr_lab, ts_lab):\n",
    "    print('\\n----------Building Ridge Regression----------')\n",
    "    param_grid = {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        'max_iter': [1000, 2000]\n",
    "    }\n",
    "    ridge = Ridge(random_state=65)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        ridge, param_grid, n_iter=20, cv=3, scoring='neg_mean_squared_error', n_jobs=1, verbose=1\n",
    "    )\n",
    "    random_search.fit(x_train, tr_lab)\n",
    "    best_model = random_search.best_estimator_\n",
    "    ts_pred = best_model.predict(x_test)\n",
    "    rmse = root_mean_squared_error(ts_lab, ts_pred)\n",
    "    mse = mean_squared_error(ts_lab, ts_pred)\n",
    "    mae = mean_absolute_error(ts_lab, ts_pred)\n",
    "    r2 = r2_score(ts_lab, ts_pred)\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"Best Cross-Validation Score (neg MSE): {random_search.best_score_:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lasso_regression(x_train, x_test, tr_lab, ts_lab):\n",
    "    print('\\n----------Building Lasso Regression----------')\n",
    "    param_grid = {\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "        'max_iter': [1000, 2000]\n",
    "    }\n",
    "    lasso = Lasso(random_state=65)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        lasso, param_grid, n_iter=20, cv=3, scoring='neg_mean_squared_error', n_jobs=1, verbose=1\n",
    "    )\n",
    "    random_search.fit(x_train, tr_lab)\n",
    "    best_model = random_search.best_estimator_\n",
    "    ts_pred = best_model.predict(x_test)\n",
    "    rmse = root_mean_squared_error(ts_lab, ts_pred)\n",
    "    mse = mean_squared_error(ts_lab, ts_pred)\n",
    "    mae = mean_absolute_error(ts_lab, ts_pred)\n",
    "    r2 = r2_score(ts_lab, ts_pred)\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"Best Cross-Validation Score (neg MSE): {random_search.best_score_:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gradient_boosting_regressor(x_train, x_test, tr_lab, ts_lab):\n",
    "    print('\\n----------Building Gradient Boosting Regression----------')\n",
    "    print(\"Shape of x_train in GradientBoosting:\", x_train.shape)\n",
    "    print(\"Shape of x_test in GradientBoosting:\", x_test.shape)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'subsample': [0.7, 0.8, 1.0],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    gbr = GradientBoostingRegressor(random_state=65, warm_start=True)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        gbr, param_grid, n_iter=20, cv=3, scoring='neg_mean_squared_error', n_jobs=1, verbose=1\n",
    "    )\n",
    "    random_search.fit(x_train, tr_lab)\n",
    "    best_model = random_search.best_estimator_\n",
    "    ts_pred = best_model.predict(x_test)\n",
    "    rmse = root_mean_squared_error(ts_lab, ts_pred)\n",
    "    mse = mean_squared_error(ts_lab, ts_pred)\n",
    "    mae = mean_absolute_error(ts_lab, ts_pred)\n",
    "    r2 = r2_score(ts_lab, ts_pred)\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"Best Cross-Validation Score (neg MSE): {random_search.best_score_:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models_dict, x_test, ts_lab):\n",
    "    print('\\n----------Comparing Models---------')\n",
    "    print(\"Shape of x_test in compare_models:\", x_test.shape)\n",
    "    results = {}\n",
    "    for name, model in models_dict.items():\n",
    "        ts_pred = model.predict(x_test)\n",
    "        rmse = root_mean_squared_error(ts_lab, ts_pred)\n",
    "        mse = mean_squared_error(ts_lab, ts_pred)\n",
    "        mae = mean_absolute_error(ts_lab, ts_pred)\n",
    "        r2 = r2_score(ts_lab, ts_pred)\n",
    "        results[name] = {\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2': r2,\n",
    "            'Predictions': ts_pred\n",
    "        }\n",
    "    comparison = pd.DataFrame({\n",
    "        model_name: {\n",
    "            'MSE': result['MSE'],\n",
    "            'RMSE': result['RMSE'],\n",
    "            'MAE': result['MAE'],\n",
    "            'R2': result['R2']\n",
    "        }\n",
    "        for model_name, result in results.items()\n",
    "    }).T\n",
    "    comparison = comparison.sort_values('R2', ascending=False)\n",
    "    print(comparison)\n",
    "    best_model_name = comparison.index[0]\n",
    "    best_model = models_dict[best_model_name]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    sns.barplot(ax=axes[0], x=comparison.index, y='R2', data=comparison, palette='viridis')\n",
    "    axes[0].set_title('Model R2 Score Comparison')\n",
    "    axes[0].set_xlabel('Model')\n",
    "    axes[0].set_ylabel('R2 Score')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    sns.barplot(ax=axes[1], x=comparison.index, y='RMSE', data=comparison, palette='magma')\n",
    "    axes[1].set_title('Model RMSE Comparison')\n",
    "    axes[1].set_xlabel('Model')\n",
    "    axes[1].set_ylabel('RMSE')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    plt.show()\n",
    "    return comparison, results, best_model, best_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Call for all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Building Linear Regression----------\n",
      "MSE: 28.6856\n",
      "RMSE: 5.3559\n",
      "MAE: 4.0901\n",
      "R2 Score: 0.2563\n",
      "\n",
      "----------Building Ridge Regression----------\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best Parameters: {'max_iter': 1000, 'alpha': 10.0}\n",
      "Best Cross-Validation Score (neg MSE): -28.2905\n",
      "MSE: 28.6856\n",
      "RMSE: 5.3559\n",
      "MAE: 4.0901\n",
      "R2 Score: 0.2563\n",
      "\n",
      "----------Building Lasso Regression----------\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best Parameters: {'max_iter': 1000, 'alpha': 0.001}\n",
      "Best Cross-Validation Score (neg MSE): -28.2904\n",
      "MSE: 28.6860\n",
      "RMSE: 5.3559\n",
      "MAE: 4.0900\n",
      "R2 Score: 0.2563\n",
      "\n",
      "----------Building Gradient Boosting Regression----------\n",
      "Shape of x_train in GradientBoosting: (105903, 12)\n",
      "Shape of x_test in GradientBoosting: (26476, 12)\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "def run_all_models(x_train, x_test, tr_lab, ts_lab):\n",
    "    lr = build_linear_regression(x_train, x_test, tr_lab, ts_lab)\n",
    "    ridge = build_ridge_regression(x_train, x_test, tr_lab, ts_lab)\n",
    "    lasso = build_lasso_regression(x_train, x_test, tr_lab, ts_lab)\n",
    "    gbr = build_gradient_boosting_regressor(x_train, x_test, tr_lab, ts_lab)\n",
    "    models = {\n",
    "        'Linear Regression': lr,\n",
    "        'Ridge Regression': ridge,\n",
    "        'Lasso Regression': lasso,\n",
    "        'Gradient Boosting Regression': gbr\n",
    "    }\n",
    "    comparison, results, best_model, best_model_name = compare_models(models, x_test, ts_lab)\n",
    "    pickle_path = '..\\models'\n",
    "    os.makedirs(pickle_path, exist_ok=True)\n",
    "    best_model_reg = os.path.join(pickle_path, 'best_model_reg.pkl')\n",
    "    with open(best_model_reg, 'wb') as file:\n",
    "        pickle.dump(best_model, file)\n",
    "    print(f\"\\nBest Model for Regression: {best_model_name} saved to 'best_model_reg.pkl'\")\n",
    "    return models, comparison, results, best_model, best_model_name\n",
    "\n",
    "# Run all models\n",
    "models, comparison, results, best_model, best_model_name = run_all_models(x_train, x_test, tr_lab, ts_lab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace X_new with your actual alternative dataset\n",
    "X_new = pd.read_csv(\"..\\data\\processed_data.csv\") \n",
    "X_new = X_new[selected]  # Select the same features\n",
    "X_new_scaled = scaler.transform(X_new)  # Apply the same scaler\n",
    "prediction = best_model.predict(X_new_scaled)\n",
    "print(\"Alternative predictions:\", prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
